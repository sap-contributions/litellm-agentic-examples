{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cdfb07f78e8f1f9",
   "metadata": {},
   "source": [
    "# PydanticAI example connecting to Sap Generative AI Hub via LiteLLM\n",
    "\n",
    "## [How PydanticAI works](https://ai.pydantic.dev/agents/)\n",
    "\n",
    "## LLM access via LiteLLM Proxy\n",
    "PydanticAI Agents supports the [LiteLLM Proxy](https://docs.ag2.ai/latest/docs/user-guide/models/litellm-proxy-server/installation/) for access via OpenAI API calls.\n",
    "\n",
    "Follow the details in [LiteLLM Proxy setup for SAP Gen. AI Hub](../PROXY_SETUP.md)\n",
    "\n",
    "## Installation\n",
    "%pip install pydantic-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790af34d5958882",
   "metadata": {},
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "LITELLM_PROXY_API_KEY=sk-1234\n",
    "PROXY_BASE_URL=http://localhost:4000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04a3b39ede7e19",
   "metadata": {},
   "source": [
    "## Run the PydanticAI with LiteLLM and SAP LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import litellm\n",
    "from dotenv import load_dotenv\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.litellm import LiteLLMProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990acd3624c9c6a",
   "metadata": {},
   "source": [
    "Load your credentials as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"PROXY_BASE_URL\")\n",
    "api_key = os.getenv(\"LITELLM_PROXY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269fa946fb812f7",
   "metadata": {},
   "source": [
    "Define the model with OpenAIChatModel object with LiteLLMProvider object with your proxy credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913f98e7c7d46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIChatModel(\n",
    "    \"sap/gpt-5\",\n",
    "    provider=LiteLLMProvider(\n",
    "        api_base=api_base,\n",
    "        api_key=api_key,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b526fce1c0c88",
   "metadata": {},
   "source": [
    "Define the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ec515fbd419ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a helpful weather assistant. \"\n",
    "    \"When the user asks about a specific city, \"\n",
    "    \"use the 'get_weather' tool to find the weather information. \"\n",
    "    \"Provide the TV weather report in two sentences including a small joke.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f44b489bff614",
   "metadata": {},
   "source": [
    "Define the agent tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbd586",
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent.tool\n",
    "def get_weather(city: RunContext[str]) -> str:\n",
    "    \"\"\"Mock function\"\"\"\n",
    "    city_normalized = city.prompt.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20째C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb982c9ec829ba80",
   "metadata": {},
   "source": [
    "Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd61c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await agent.run(\"London\")\n",
    "print(result.output)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
