{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PydanticAI example with LiteLLM Proxy and SAP LLMs\n",
    "\n",
    "## [How PydanticAI works](https://ai.pydantic.dev/agents/)\n",
    "## [LiteLLM Proxy setup for SAP models](../proxy_set_up.ipynb)\n",
    "\n",
    "## Installation"
   ],
   "id": "6cdfb07f78e8f1f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install pydantic-ai litellm",
   "id": "af25ed98db069a41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "\"PROXY_MASTER_KEY\": sk-1234,\n",
    "\"PROXY_BASE_URL\": \"http://localhost:4000\"\n",
    "```"
   ],
   "id": "5790af34d5958882"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the PydanticAI with LiteLLM and SAP LLMs",
   "id": "9d04a3b39ede7e19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.litellm import LiteLLMProvider\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import litellm"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load your credentials as environment variables.",
   "id": "b990acd3624c9c6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94f188",
   "metadata": {},
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"LITELLM_ROXY_URL\")\n",
    "api_key = os.getenv(\"LITELLM_MASTER_KEY\")"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the model with OpenAIChatModel object with LiteLLMProvider object with your proxy credentials",
   "id": "6269fa946fb812f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = OpenAIChatModel(\n",
    "    \"sap/gpt-5\",\n",
    "    provider=LiteLLMProvider(\n",
    "        api_base=api_base,\n",
    "        api_key=api_key,\n",
    "    ),\n",
    ")"
   ],
   "id": "2913f98e7c7d46b9",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the agent",
   "id": "ab6b526fce1c0c88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a helpful weather assistant. \"\n",
    "    \"When the user send you asks a specific city, \"\n",
    "    \"use the 'get_weather' tool to find the information about the weather. \"\n",
    "    \"Aser with TV weather report in two sentences, include small jok\",\n",
    ")"
   ],
   "id": "266ec515fbd419ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the agent tool.",
   "id": "446f44b489bff614"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbd586",
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent.tool\n",
    "def get_weather(city: RunContext[str]) -> str:\n",
    "    \"\"\"Mock function\"\"\"\n",
    "    city_normalized = city.prompt.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20째C.\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run agent",
   "id": "cb982c9ec829ba80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd61c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.run_sync(\"London\")\n",
    "print(result.output)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
