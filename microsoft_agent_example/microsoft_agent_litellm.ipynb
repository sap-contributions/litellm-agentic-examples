{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bea56351cb9cc0b",
   "metadata": {},
   "source": [
    "# Microsoft Agents example with LiteLLM Proxy and SAP LLMs\n",
    "\n",
    "## [How Microsoft Agents works](https://learn.microsoft.com/en-us/microsoft-365/agents-sdk/quickstart-python)\n",
    "## [LiteLLM Proxy set up for SAP models](../proxy_set_up.ipynb)\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "id": "b992c431fc5420dc",
   "metadata": {},
   "source": "%pip install agent-framework litellm",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6745981501b638b2",
   "metadata": {},
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "LITELLM_PROXY_API_KEY=sk-1234\n",
    "PROXY_BASE_URL=http://localhost:4000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35088ae2fa74b98b",
   "metadata": {},
   "source": [
    "## Run the Microsoft Agents with LiteLLM and SAP LLMs"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb0f98e0748a09dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:51:38.794328Z",
     "start_time": "2025-12-05T08:51:38.644461Z"
    }
   },
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import Annotated\n",
    "\n",
    "import litellm\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import Field"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mcp.types' has no attribute 'ToolUseContent'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Annotated\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01magent_framework\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatAgent\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01magent_framework\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mopenai\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m OpenAIChatClient\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdotenv\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/agent_framework/__init__.py:12\u001B[39m\n\u001B[32m      9\u001B[39m     _version = \u001B[33m\"\u001B[39m\u001B[33m0.0.0\u001B[39m\u001B[33m\"\u001B[39m  \u001B[38;5;66;03m# Fallback for development mode\u001B[39;00m\n\u001B[32m     10\u001B[39m __version__: Final[\u001B[38;5;28mstr\u001B[39m] = _version\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_agents\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_clients\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/agent_framework/_agents.py:18\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmcp\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mshared\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexceptions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m McpError\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpydantic\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseModel, Field, create_model\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_clients\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseChatClient, ChatClientProtocol\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_logger\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_mcp\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LOG_LEVEL_MAPPING, MCPTool\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:11\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpydantic\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseModel\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_logger\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_mcp\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m MCPTool\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_memory\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AggregateContextProvider, ContextProvider\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_middleware\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     14\u001B[39m     ChatMiddleware,\n\u001B[32m     15\u001B[39m     ChatMiddlewareCallable,\n\u001B[32m   (...)\u001B[39m\u001B[32m     18\u001B[39m     Middleware,\n\u001B[32m     19\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/agent_framework/_mcp.py:134\u001B[39m\n\u001B[32m    124\u001B[39m         result_contents.extend(contents)\n\u001B[32m    125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result_contents\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_mcp_type_to_ai_content\u001B[39m(\n\u001B[32m    129\u001B[39m     mcp_type: types.ImageContent\n\u001B[32m    130\u001B[39m     | types.TextContent\n\u001B[32m    131\u001B[39m     | types.AudioContent\n\u001B[32m    132\u001B[39m     | types.EmbeddedResource\n\u001B[32m    133\u001B[39m     | types.ResourceLink\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m     | \u001B[43mtypes\u001B[49m\u001B[43m.\u001B[49m\u001B[43mToolUseContent\u001B[49m\n\u001B[32m    135\u001B[39m     | types.ToolResultContent\n\u001B[32m    136\u001B[39m     | Sequence[\n\u001B[32m    137\u001B[39m         types.ImageContent\n\u001B[32m    138\u001B[39m         | types.TextContent\n\u001B[32m    139\u001B[39m         | types.AudioContent\n\u001B[32m    140\u001B[39m         | types.EmbeddedResource\n\u001B[32m    141\u001B[39m         | types.ResourceLink\n\u001B[32m    142\u001B[39m         | types.ToolUseContent\n\u001B[32m    143\u001B[39m         | types.ToolResultContent\n\u001B[32m    144\u001B[39m     ],\n\u001B[32m    145\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m[Contents]:\n\u001B[32m    146\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Convert a MCP type to a Agent Framework type.\"\"\"\u001B[39;00m\n\u001B[32m    147\u001B[39m     mcp_types = mcp_type \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mcp_type, Sequence) \u001B[38;5;28;01melse\u001B[39;00m [mcp_type]\n",
      "\u001B[31mAttributeError\u001B[39m: module 'mcp.types' has no attribute 'ToolUseContent'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "8cff6eec0d58e35a",
   "metadata": {},
   "source": [
    "Load your credentials as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3e175",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"PROXY_BASE_URL\")\n",
    "api_key = os.getenv(\"LITELLM_PROXY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c07ca508b0a5f",
   "metadata": {},
   "source": [
    "Define the agent tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050b677",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    city: Annotated[str, Field(description=\"The location to get weather for\")]\n",
    ") -> str:\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20째C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e121844fa464f",
   "metadata": {},
   "source": [
    "Create agent using OpenAIClient with the proxy credentials and the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa404037",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "agent = ChatAgent(\n",
    "    chat_client=OpenAIChatClient(model_id=\"sap/gpt-4o\",\n",
    "                                 api_key=api_key,\n",
    "                                 base_url=api_base,),\n",
    "    instructions=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, write a couple sentences for \"\n",
    "                \"TV weather report in the city, that will be include small jok\",\n",
    "    name=\"litellm_agent\",\n",
    "    tools=[get_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ee539e25bb85f",
   "metadata": {},
   "source": [
    "Define the async function with agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682555d9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def tools_example():\n",
    "    result = await agent.run(\"What's the weather like in Tokyo?\")\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f9ca929193962",
   "metadata": {},
   "source": [
    "Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5777cc",
   "metadata": {},
   "outputs": [],
   "source": "await tools_example()"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
