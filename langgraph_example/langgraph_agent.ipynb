{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e368ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Langchain agent that uses a weather tool.\n",
    "This example uses the Langgraph Functional API according to: https://docs.langchain.com/oss/python/langgraph/quickstart#use-the-functional-api\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_litellm import ChatLiteLLM\n",
    "from langgraph.graph import add_messages\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    ToolCall,\n",
    ")\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.func import entrypoint, task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9addbd58",
   "metadata": {},
   "source": [
    "Step 1: Define model and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatLiteLLM(model=\"sap/gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25144dab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Define weather tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83946925",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"\n",
    "    Returns weather information for a given city.\n",
    "    :param city:\n",
    "    :return: weather information\n",
    "    \"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20째C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673e6ff",
   "metadata": {},
   "source": [
    "Augment the LLM with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c534f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_weather]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f5c58",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Step 2: Define model node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0673f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@task\n",
    "def call_llm(messages: list[BaseMessage]):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "    return model_with_tools.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks you about a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information about the weather. \"\n",
    "                \"Answer with a TV weather report in two sentences, including a small joke.\"\n",
    "            )\n",
    "        ]\n",
    "        + messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d2f88",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Step 3: Define tool node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e60be1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@task\n",
    "def call_tool(tool_call: ToolCall):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "    tool = tools_by_name[tool_call[\"name\"]]\n",
    "    return tool.invoke(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c986fe6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Step 4: Define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@entrypoint()\n",
    "def agent(messages: list[BaseMessage]):\n",
    "    model_response = call_llm(messages).result()\n",
    "\n",
    "    while True:\n",
    "        if not model_response.tool_calls:\n",
    "            break\n",
    "\n",
    "        # Execute tools\n",
    "        tool_result_futures = [\n",
    "            call_tool(tool_call) for tool_call in model_response.tool_calls\n",
    "        ]\n",
    "        tool_results = [fut.result() for fut in tool_result_futures]\n",
    "        messages = add_messages(messages, [model_response, *tool_results])\n",
    "        model_response = call_llm(messages).result()\n",
    "\n",
    "    messages = add_messages(messages, model_response)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3193df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke\n",
    "city = input(\"Input city: \")\n",
    "input_message = [HumanMessage(content=f\"What's the weather in {city}?\")]\n",
    "for chunk in agent.stream(input_message, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
