{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AG2 example with LiteLLM Proxy and SAP LLMs\n",
    "\n",
    "## [How AG2 works](https://docs.ag2.ai/latest/)\n",
    "\n",
    "## LLM access via LiteLLM Proxy\n",
    "AG2 supports the [LiteLLM Proxy](https://docs.ag2.ai/latest/docs/user-guide/models/litellm-proxy-server/installation/) for access via OpenAI API calls.\n",
    "\n",
    "Follow details in [LiteLLM Proxy setup for SAP Gen. AI Hub](../proxy_set_up.ipynb)\n",
    "\n",
    "## Installation"
   ],
   "id": "b63a1db1d250c535"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install 'ag2[openai]'",
   "id": "ca03c61aff5a08f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install litellm",
   "id": "35becf081cd24489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "\"PROXY_MASTER_KEY\": sk-1234,\n",
    "\"PROXY_BASE_URL\": \"http://localhost:4000\"\n",
    "```"
   ],
   "id": "22ebca03bac76ba5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the CrewAI with LiteLLM and SAP LLMs",
   "id": "858f6b3463faf747"
  },
  {
   "cell_type": "code",
   "id": "a14a9674",
   "metadata": {},
   "source": [
    "import os\n",
    "import litellm\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Any\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from autogen.agentchat import initiate_group_chat"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load your credentials as environment variables.",
   "id": "73a3e1d40d4cd663"
  },
  {
   "cell_type": "code",
   "id": "ca983253",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"LITELLM_ROXY_URL\")\n",
    "api_key = os.getenv(\"LITELLM_MASTER_KEY\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up the model with your proxy params",
   "id": "ba1cb106a07d2c91"
  },
  {
   "cell_type": "code",
   "id": "ac2b2e2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": "llm_config = LLMConfig(config_list={\"model\": \"sap/gpt-4o\", \"base_url\": api_base, \"api_key\": api_key})",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the agent tools.",
   "id": "58d436d1201b3f09"
  },
  {
   "metadata": {
    "lines_to_next_cell": 1
   },
   "cell_type": "code",
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Moke function\"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20째C.\""
   ],
   "id": "6b682cf86a8e9a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the function for check if agent conversation is finished",
   "id": "f0a8291971a73884"
  },
  {
   "cell_type": "code",
   "id": "b2a11076",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "def is_termination_msg(msg: dict[str, Any]) -> bool:\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    return (content is not None) and \"==== REPORT GENERATED ====\" in content"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the Agent with the SAP LLM and the tool.",
   "id": "dcb445ad60e2b732"
  },
  {
   "cell_type": "code",
   "id": "0dc2754f",
   "metadata": {},
   "source": [
    "assistant = ConversableAgent(name=\"assistant\",\n",
    "                             llm_config=llm_config,\n",
    "                             system_message=\"You are a helpful weather assistant. \"\n",
    "                                            \"When the user asks for the weather in a specific city, \"\n",
    "                                            \"use the 'get_weather' tool to find the information. \"\n",
    "                                            \"If the tool returns an error, inform the user politely. \"\n",
    "                                            \"If the tool is successful, write a couple sentences for \"\n",
    "                                            \"TV weather report in the city, that will be include small jok.\"\n",
    "                                            \"Once you've generated the report append the below in the summary:\"\n",
    "                                            \"==== REPORT GENERATED ====\",\n",
    "                             functions=[get_weather])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up the conversation pattern with the agent, model and function for conversation termination",
   "id": "12d0d4b3b39c51b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pattern = AutoPattern(initial_agent=assistant,\n",
    "                      agents=[assistant],\n",
    "                      group_manager_args={\n",
    "                          \"llm_config\": llm_config,\n",
    "                          \"is_termination_msg\": is_termination_msg\n",
    "                      },\n",
    "                      )"
   ],
   "id": "1e0535bad5b9abde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run the conversation with message",
   "id": "c7f923590921a102"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result, _, _ = initiate_group_chat(pattern=pattern,\n",
    "                                   messages=\"What is the weather like in Tbilisi?\",\n",
    "                                   )"
   ],
   "id": "1f981e754e2a2dbb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
