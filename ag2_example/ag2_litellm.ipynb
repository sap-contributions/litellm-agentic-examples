{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ag2[openai]\n",
    "import os\n",
    "import litellm\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Any\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from autogen.agentchat import initiate_group_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ed6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable\n",
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca983253",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "api_base = os.getenv(\"LITELLM_ROXY_URL\")\n",
    "api_key = os.getenv(\"LITELLM_MASTER_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5debdb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# tool definition\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Moke function\"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20째C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b2e2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# set up model\n",
    "llm_config = LLMConfig(config_list={\"model\": \"sap/gpt-4o\", \"base_url\": api_base, \"api_key\": api_key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a11076",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#setup function for finish conversation\n",
    "def is_termination_msg(msg: dict[str, Any]) -> bool:\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    return (content is not None) and \"==== REPORT GENERATED ====\" in content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup agent\n",
    "assistant = ConversableAgent(name=\"assistant\",\n",
    "                             llm_config=llm_config,\n",
    "                             system_message=\"You are a helpful weather assistant. \"\n",
    "                                            \"When the user asks for the weather in a specific city, \"\n",
    "                                            \"use the 'get_weather' tool to find the information. \"\n",
    "                                            \"If the tool returns an error, inform the user politely. \"\n",
    "                                            \"If the tool is successful, write a couple sentences for \"\n",
    "                                            \"TV weather report in the city, that will be include small jok.\"\n",
    "                                            \"Once you've generated the report append the below in the summary:\"\n",
    "                                            \"==== REPORT GENERATED ====\",\n",
    "                             functions=[get_weather])\n",
    "# setup pattern\n",
    "pattern = AutoPattern(initial_agent=assistant,\n",
    "                      agents=[assistant],\n",
    "                      group_manager_args={\n",
    "                          \"llm_config\": llm_config,\n",
    "                          \"is_termination_msg\": is_termination_msg\n",
    "                      },\n",
    "                      )\n",
    "# start conversation\n",
    "result, _, _ = initiate_group_chat(pattern=pattern,\n",
    "                                   messages=\"What is the weather like in Tbilisi?\",\n",
    "                                   )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
