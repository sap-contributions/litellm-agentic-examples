{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63a1db1d250c535",
   "metadata": {},
   "source": [
    "# AG2 example connecting to Sap Generative AI Hub via LiteLLM Proxy\n",
    "\n",
    "## [How AG2 works](https://docs.ag2.ai/latest/)\n",
    "\n",
    "## LLM access via LiteLLM Proxy\n",
    "AG2 supports the [LiteLLM Proxy](https://docs.ag2.ai/latest/docs/user-guide/models/litellm-proxy-server/installation/) for access via OpenAI API calls.\n",
    "Follow the details in [LiteLLM Proxy setup for SAP Gen. AI Hub](../proxy_set_up.ipynb)\n",
    "\n",
    "## Installation\n",
    "%pip install \"ag2[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebca03bac76ba5",
   "metadata": {},
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "LITELLM_PROXY_API_KEY=sk-1234\n",
    "PROXY_BASE_URL=http://localhost:4000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f6b3463faf747",
   "metadata": {},
   "source": [
    "## Run the CrewAI with LiteLLM and SAP LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "import litellm\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3e1d40d4cd663",
   "metadata": {},
   "source": [
    "Load your credentials as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca983253",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"PROXY_BASE_URL\")\n",
    "api_key = os.getenv(\"LITELLM_PROXY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1cb106a07d2c91",
   "metadata": {},
   "source": [
    "Set up the model with your proxy params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b2e2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "llm_config = LLMConfig(config_list={\"model\": \"sap/gpt-4o\", \"base_url\": api_base, \"api_key\": api_key})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d436d1201b3f09",
   "metadata": {},
   "source": [
    "Define the agent tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b682cf86a8e9a2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Moke function\"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20째C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8291971a73884",
   "metadata": {},
   "source": [
    "Define the function for check if agent conversation is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a11076",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def is_termination_msg(msg: dict[str, Any]) -> bool:\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    return (content is not None) and \"==== REPORT GENERATED ====\" in content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb445ad60e2b732",
   "metadata": {},
   "source": [
    "Define the Agent with the SAP LLM and the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2754f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "assistant = ConversableAgent(name=\"assistant\",\n",
    "                             llm_config=llm_config,\n",
    "                             system_message=\"\"\"\n",
    "                                        You are a helpful weather assistant.\n",
    "                                        When the user asks for the weather in a specific city, use the 'get_weather' tool to find the information.\n",
    "                                        If the tool returns an error, inform the user politely.\n",
    "                                        If the tool is successful, write a couple of sentences for a TV weather report in the given city including a small joke.\"\n",
    "                                        Once you've generated the report append this to the summary:\n",
    "                                        ==== REPORT GENERATED ====\n",
    "                                        \"\"\",\n",
    "                             functions=[get_weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0d4b3b39c51b6",
   "metadata": {},
   "source": [
    "Set up the conversation pattern with the agent, model and function for conversation termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0535bad5b9abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = AutoPattern(initial_agent=assistant,\n",
    "                      agents=[assistant],\n",
    "                      group_manager_args={\n",
    "                          \"llm_config\": llm_config,\n",
    "                          \"is_termination_msg\": is_termination_msg\n",
    "                      },\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f923590921a102",
   "metadata": {},
   "source": [
    "Run the conversation with message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f981e754e2a2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _, _ = initiate_group_chat(pattern=pattern,\n",
    "                                   messages=\"What is the weather like in Tbilisi?\",\n",
    "                                   )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
