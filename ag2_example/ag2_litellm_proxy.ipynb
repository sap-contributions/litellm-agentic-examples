{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63a1db1d250c535",
   "metadata": {},
   "source": [
    "# AG2 example connecting to Sap Generative AI Hub via LiteLLM Proxy\n",
    "\n",
    "## [How AG2 works](https://docs.ag2.ai/latest/)\n",
    "\n",
    "## LLM access via LiteLLM Proxy\n",
    "AG2 supports the [LiteLLM Proxy](https://docs.ag2.ai/latest/docs/user-guide/models/litellm-proxy-server/installation/) for access via OpenAI API calls.\n",
    "\n",
    "## Installation\n",
    "Follow details in [LiteLLM Proxy setup for SAP Gen. AI Hub](../proxy_set_up.ipynb)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:38:24.286327Z",
     "start_time": "2025-12-05T08:38:21.429955Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install \"ag2[openai]\"",
   "id": "366125f23d71471f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ag2[openai] in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (4.11.0)\r\n",
      "Requirement already satisfied: diskcache in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (5.6.3)\r\n",
      "Requirement already satisfied: docker in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (7.1.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (0.28.1)\r\n",
      "Requirement already satisfied: packaging in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (25.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (2.12.3)\r\n",
      "Requirement already satisfied: python-dotenv in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (1.2.1)\r\n",
      "Requirement already satisfied: termcolor in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (3.2.0)\r\n",
      "Requirement already satisfied: tiktoken in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (0.12.0)\r\n",
      "Requirement already satisfied: openai>=1.99.3 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from ag2[openai]) (2.8.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (3.11)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (1.3.1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (4.15.0)\r\n",
      "Requirement already satisfied: certifi in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from httpx<1,>=0.28.1->ag2[openai]) (2025.10.5)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from httpx<1,>=0.28.1->ag2[openai]) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2[openai]) (0.16.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from openai>=1.99.3->ag2[openai]) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from openai>=1.99.3->ag2[openai]) (0.10.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from openai>=1.99.3->ag2[openai]) (4.67.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (2.41.4)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.4.2)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from docker->ag2[openai]) (2.32.5)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from docker->ag2[openai]) (2.3.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from tiktoken->ag2[openai]) (2025.11.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages (from requests>=2.26.0->docker->ag2[openai]) (3.4.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "22ebca03bac76ba5",
   "metadata": {},
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "LITELLM_PROXY_API_KEY=sk-1234\n",
    "PROXY_BASE_URL=http://localhost:4000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f6b3463faf747",
   "metadata": {},
   "source": [
    "## Run the CrewAI with LiteLLM and SAP LLMs"
   ]
  },
  {
   "cell_type": "code",
   "id": "a14a9674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:45.018148Z",
     "start_time": "2025-12-05T08:37:40.480510Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "import litellm\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vasilisa/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "73a3e1d40d4cd663",
   "metadata": {},
   "source": [
    "Load your credentials as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "id": "ca983253",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:45.024594Z",
     "start_time": "2025-12-05T08:37:45.021705Z"
    }
   },
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"PROXY_BASE_URL\")\n",
    "api_key = os.getenv(\"LITELLM_PROXY_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "ba1cb106a07d2c91",
   "metadata": {},
   "source": [
    "Set up the model with your proxy params"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac2b2e2d",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:45.031398Z",
     "start_time": "2025-12-05T08:37:45.029934Z"
    }
   },
   "source": [
    "llm_config = LLMConfig(config_list={\"model\": \"sap/gpt-4o\", \"base_url\": api_base, \"api_key\": api_key})"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "58d436d1201b3f09",
   "metadata": {},
   "source": [
    "Define the agent tools."
   ]
  },
  {
   "cell_type": "code",
   "id": "6b682cf86a8e9a2",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:45.035203Z",
     "start_time": "2025-12-05T08:37:45.033693Z"
    }
   },
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Moke function\"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25°C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15°C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18°C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"The weather in {city} is sunny with a temperature of 20°C.\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "f0a8291971a73884",
   "metadata": {},
   "source": [
    "Define the function for check if agent conversation is finished"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2a11076",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:45.038646Z",
     "start_time": "2025-12-05T08:37:45.037389Z"
    }
   },
   "source": [
    "def is_termination_msg(msg: dict[str, Any]) -> bool:\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    return (content is not None) and \"==== REPORT GENERATED ====\" in content"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "dcb445ad60e2b732",
   "metadata": {},
   "source": [
    "Define the Agent with the SAP LLM and the tool."
   ]
  },
  {
   "cell_type": "code",
   "id": "0dc2754f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:45.065792Z",
     "start_time": "2025-12-05T08:37:45.040685Z"
    }
   },
   "source": [
    "assistant = ConversableAgent(name=\"assistant\",\n",
    "                             llm_config=llm_config,\n",
    "                             system_message=\"You are a helpful weather assistant. \"\n",
    "                                            \"When the user asks for the weather in a specific city, \"\n",
    "                                            \"use the 'get_weather' tool to find the information. \"\n",
    "                                            \"If the tool returns an error, inform the user politely. \"\n",
    "                                            \"If the tool is successful, write a couple sentences for a \"\n",
    "                                            \"TV weather report in the city, that will be include small joke.\"\n",
    "                                            \"Once you've generated the report append this to the summary:\"\n",
    "                                            \"==== REPORT GENERATED ====\",\n",
    "                             functions=[get_weather])"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "12d0d4b3b39c51b6",
   "metadata": {},
   "source": [
    "Set up the conversation pattern with the agent, model and function for conversation termination"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e0535bad5b9abde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:45.070031Z",
     "start_time": "2025-12-05T08:37:45.068676Z"
    }
   },
   "source": [
    "pattern = AutoPattern(initial_agent=assistant,\n",
    "                      agents=[assistant],\n",
    "                      group_manager_args={\n",
    "                          \"llm_config\": llm_config,\n",
    "                          \"is_termination_msg\": is_termination_msg\n",
    "                      },\n",
    "                      )"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "c7f923590921a102",
   "metadata": {},
   "source": [
    "Run the conversation with message"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f981e754e2a2dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:37:49.441468Z",
     "start_time": "2025-12-05T08:37:45.072465Z"
    }
   },
   "source": [
    "result, _, _ = initiate_group_chat(pattern=pattern,\n",
    "                                   messages=\"What is the weather like in Tbilisi?\",\n",
    "                                   )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33m_User\u001B[0m (to chat_manager):\n",
      "\n",
      "What is the weather like in Tbilisi?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[32m\n",
      "Next speaker: assistant\n",
      "\u001B[0m\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n",
      "\u001B[33massistant\u001B[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\u001B[32m***** Suggested tool call (call_Aw8yVKzSOju1DD0zuDMZs8ZT): get_weather *****\u001B[0m\n",
      "Arguments: \n",
      "{\"city\":\"Tbilisi\"}\n",
      "\u001B[32m****************************************************************************\u001B[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[32m\n",
      "Next speaker: _Group_Tool_Executor\n",
      "\u001B[0m\n",
      "\u001B[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_weather...\n",
      "Call ID: call_Aw8yVKzSOju1DD0zuDMZs8ZT\n",
      "Input arguments: {'city': 'Tbilisi'}\u001B[0m\n",
      "\u001B[35m\n",
      ">>>>>>>> EXECUTED FUNCTION get_weather...\n",
      "Call ID: call_Aw8yVKzSOju1DD0zuDMZs8ZT\n",
      "Input arguments: {'city': 'Tbilisi'}\n",
      "Output:\n",
      "The weather in Tbilisi is sunny with a temperature of 20°C.\u001B[0m\n",
      "\u001B[33m_Group_Tool_Executor\u001B[0m (to chat_manager):\n",
      "\n",
      "\u001B[32m***** Response from calling tool (call_Aw8yVKzSOju1DD0zuDMZs8ZT) *****\u001B[0m\n",
      "The weather in Tbilisi is sunny with a temperature of 20°C.\n",
      "\u001B[32m**********************************************************************\u001B[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[32m\n",
      "Next speaker: assistant\n",
      "\u001B[0m\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n",
      "\u001B[33massistant\u001B[0m (to chat_manager):\n",
      "\n",
      "Good afternoon, Tbilisi! Today, you can enjoy sunny skies with a comfortable temperature of 20°C. It's a perfect day to soak up some sun—just don't forget your sunscreen, unless you're planning to tango with a tanning bed!==== REPORT GENERATED ====\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> TERMINATING RUN (95c7250c-2c60-488d-99b9-9be6cc616a54): Termination message condition on the GroupChatManager 'chat_manager' met\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
