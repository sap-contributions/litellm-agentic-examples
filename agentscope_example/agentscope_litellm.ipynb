{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AgentScope example with LiteLLM Proxy and SAP LLMs\n",
    "\n",
    "## [How AgentScope works](https://doc.agentscope.io/tutorial/)\n",
    "\n",
    "## LLM access via LiteLLM Proxy\n",
    "AgentScope supports the [LiteLLM Proxy](https://docs.ag2.ai/latest/docs/user-guide/models/litellm-proxy-server/installation/) for access via OpenAI API calls.\n",
    "\n",
    "Follow details in [LiteLLM Proxy setup for SAP Gen. AI Hub](../proxy_set_up.ipynb)\n",
    "\n",
    "## Installation"
   ],
   "id": "4bb4f4ab484ea4c8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "%pip install agentscope litellm",
   "id": "7ce45f7ae9c7e1ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "\"PROXY_MASTER_KEY\": sk-1234,\n",
    "\"PROXY_BASE_URL\": \"http://localhost:4000\"\n",
    "```"
   ],
   "id": "102631d376927ee7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the AgentScope with LiteLLM and SAP LLMs",
   "id": "408fd62825f8b955"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import litellm\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from agentscope.model import OpenAIChatModel\n",
    "from agentscope.tool import ToolResponse, Toolkit\n",
    "from agentscope.message import TextBlock\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.message import Msg"
   ],
   "id": "b3f5fa03d417688a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load your credentials as environment variables.",
   "id": "d20a325453af7922"
  },
  {
   "cell_type": "code",
   "id": "738e931b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"LITELLM_ROXY_URL\")\n",
    "api_key = os.getenv(\"LITELLM_MASTER_KEY\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up the model with your proxy params",
   "id": "1488cf79b30e71ed"
  },
  {
   "cell_type": "code",
   "id": "51cdafae",
   "metadata": {},
   "source": [
    "sap_model = OpenAIChatModel(model_name='sap/gpt-4o',\n",
    "                            api_key=api_key,\n",
    "                            client_args={\"base_url\": api_base},\n",
    "                            stream=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the agent tools with a properly formatted docstring. Including the Args section is necessary for the correct functioning of the tool. Also the function must return its response as a ToolResponse object.",
   "id": "d8c2357ecd49050f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_weather(city: str) -> ToolResponse:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "    Args:\n",
    "        city (str): The name of the city to retrieve weather information for.\n",
    "            Examples: \"New York\", \"London\", \"Tokyo\".\n",
    "    \"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return ToolResponse(content=[\n",
    "            TextBlock(type=\"text\",\n",
    "                      text=mock_weather_db[city_normalized])\n",
    "        ])\n",
    "    else:\n",
    "        return ToolResponse(content=[\n",
    "            TextBlock(type=\"text\",\n",
    "                      text=f\"The weather in {city} is sunny with a temperature of 20째C.\")\n",
    "        ])"
   ],
   "id": "fcb264460a6acfe3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Register the tools in a toolkit",
   "id": "8f678cf6b2cc3eee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "toolkit = Toolkit()\n",
    "toolkit.register_tool_function(get_weather)"
   ],
   "id": "fcbad89575f9189d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the Agent with the SAP LLM and the tool, memory and formatter objects.",
   "id": "25c8f76ac746be91"
  },
  {
   "cell_type": "code",
   "id": "79bd8c6c",
   "metadata": {},
   "source": [
    "agent = ReActAgent(\n",
    "        name=\"weather agent\",\n",
    "        sys_prompt=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, write a couple sentences for \"\n",
    "                \"TV weather report in the city, that will be include small jok\",\n",
    "        model=sap_model,\n",
    "        formatter=DashScopeChatFormatter(),\n",
    "        toolkit=toolkit,\n",
    "        memory=InMemoryMemory(),\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a message",
   "id": "41084e27e3d35b72"
  },
  {
   "cell_type": "code",
   "id": "1e909669",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "msg = Msg(\n",
    "        name=\"user\",\n",
    "        content=\"What is the weather like in Tbilisi?\",\n",
    "        role=\"user\",\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run agent inside the async function",
   "id": "78543e6c51ef5ddd"
  },
  {
   "cell_type": "code",
   "id": "6ca4394b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "async def run_conversation():\n",
    "    result = await agent(msg)\n",
    "    print(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run the conversation function",
   "id": "910180b1e68326dc"
  },
  {
   "cell_type": "code",
   "id": "d3cad2cb",
   "metadata": {},
   "source": [
    "asyncio.run(run_conversation())"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
