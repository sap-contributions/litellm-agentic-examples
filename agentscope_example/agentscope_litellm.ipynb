{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AgentScope example with LiteLLM Proxy and SAP LLMs\n",
    "\n",
    "## [How AgentScope works](https://doc.agentscope.io/tutorial/)\n",
    "## [LiteLLM Proxy set pu for SAP models](../proxy_set_up.ipynb)\n",
    "\n",
    "## Installation"
   ],
   "id": "4bb4f4ab484ea4c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install agentscope",
   "id": "7ce45f7ae9c7e1ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install litellm",
   "id": "96abc57ead5cc667"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "\"PROXY_MASTER_KEY\": sk-1234,\n",
    "\"PROXY_BASE_URL\": \"http://localhost:4000\"\n",
    "```"
   ],
   "id": "102631d376927ee7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the AgentScope with LiteLLM and SAP LLMs",
   "id": "408fd62825f8b955"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T09:23:09.458257Z",
     "start_time": "2025-11-07T09:23:04.802056Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01masyncio\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdotenv\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/litellm/__init__.py:21\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mintegrations\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdatadog_llm_obs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DatadogLLMObsInitParams\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mintegrations\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdatadog\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DatadogInitParams\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mllms\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcustom_httpx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mhttp_handler\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AsyncHTTPHandler, HTTPHandler\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcaching\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcaching\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Cache, DualCache, RedisCache, InMemoryCache\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcaching\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mllm_caching_handler\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LLMClientCache\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/litellm/llms/__init__.py:6\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING, Dict, Optional, Type\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m verbose_logger\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlitellm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CallTypes\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/litellm/types/utils.py:17\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      5\u001B[39m     TYPE_CHECKING,\n\u001B[32m      6\u001B[39m     Any,\n\u001B[32m   (...)\u001B[39m\u001B[32m     13\u001B[39m     Union,\n\u001B[32m     14\u001B[39m )\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01maiohttp\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FormData\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mopenai\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_models\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseModel \u001B[38;5;28;01mas\u001B[39;00m OpenAIObject\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mopenai\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01maudio\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtranscription_create_params\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FileTypes  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mopenai\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchat\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchat_completion\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatCompletion\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/__init__.py:94\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mazure\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AzureOpenAI \u001B[38;5;28;01mas\u001B[39;00m AzureOpenAI, AsyncAzureOpenAI \u001B[38;5;28;01mas\u001B[39;00m AsyncAzureOpenAI\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_old_api\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstreaming\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     95\u001B[39m     AssistantEventHandler \u001B[38;5;28;01mas\u001B[39;00m AssistantEventHandler,\n\u001B[32m     96\u001B[39m     AsyncAssistantEventHandler \u001B[38;5;28;01mas\u001B[39;00m AsyncAssistantEventHandler,\n\u001B[32m     97\u001B[39m )\n\u001B[32m     99\u001B[39m _setup_logging()\n\u001B[32m    101\u001B[39m \u001B[38;5;66;03m# Update the __module__ attribute for exported symbols so that\u001B[39;00m\n\u001B[32m    102\u001B[39m \u001B[38;5;66;03m# error messages point to this module instead of the module\u001B[39;00m\n\u001B[32m    103\u001B[39m \u001B[38;5;66;03m# it was originally defined in, e.g.\u001B[39;00m\n\u001B[32m    104\u001B[39m \u001B[38;5;66;03m# openai._exceptions.NotFoundError -> openai.NotFoundError\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/lib/streaming/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_assistants\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      2\u001B[39m     AssistantEventHandler \u001B[38;5;28;01mas\u001B[39;00m AssistantEventHandler,\n\u001B[32m      3\u001B[39m     AssistantEventHandlerT \u001B[38;5;28;01mas\u001B[39;00m AssistantEventHandlerT,\n\u001B[32m      4\u001B[39m     AssistantStreamManager \u001B[38;5;28;01mas\u001B[39;00m AssistantStreamManager,\n\u001B[32m      5\u001B[39m     AsyncAssistantEventHandler \u001B[38;5;28;01mas\u001B[39;00m AsyncAssistantEventHandler,\n\u001B[32m      6\u001B[39m     AsyncAssistantEventHandlerT \u001B[38;5;28;01mas\u001B[39;00m AsyncAssistantEventHandlerT,\n\u001B[32m      7\u001B[39m     AsyncAssistantStreamManager \u001B[38;5;28;01mas\u001B[39;00m AsyncAssistantStreamManager,\n\u001B[32m      8\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/lib/streaming/_assistants.py:14\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_models\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m construct_type\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_streaming\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Stream, AsyncStream\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbeta\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AssistantStreamEvent\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbeta\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mthreads\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     16\u001B[39m     Run,\n\u001B[32m     17\u001B[39m     Text,\n\u001B[32m   (...)\u001B[39m\u001B[32m     23\u001B[39m     MessageContentDelta,\n\u001B[32m     24\u001B[39m )\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbeta\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mthreads\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mruns\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m RunStep, ToolCall, RunStepDelta, ToolCallDelta\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/types/beta/__init__.py:14\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunction_tool_param\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FunctionToolParam \u001B[38;5;28;01mas\u001B[39;00m FunctionToolParam\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01massistant_tool_param\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AssistantToolParam \u001B[38;5;28;01mas\u001B[39;00m AssistantToolParam\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mthread_create_params\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ThreadCreateParams \u001B[38;5;28;01mas\u001B[39;00m ThreadCreateParams\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mthread_update_params\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ThreadUpdateParams \u001B[38;5;28;01mas\u001B[39;00m ThreadUpdateParams\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01massistant_list_params\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AssistantListParams \u001B[38;5;28;01mas\u001B[39;00m AssistantListParams\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/types/beta/thread_create_params.py:11\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mshared_params\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetadata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Metadata\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcode_interpreter_tool_param\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CodeInterpreterToolParam\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mthreads\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmessage_content_part_param\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m MessageContentPartParam\n\u001B[32m     13\u001B[39m __all__ = [\n\u001B[32m     14\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mThreadCreateParams\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     15\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     26\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mToolResourcesFileSearchVectorStoreChunkingStrategyStaticStatic\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     27\u001B[39m ]\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mThreadCreateParams\u001B[39;00m(TypedDict, total=\u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/types/beta/threads/__init__.py:5\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m__future__\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m annotations\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mrun\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Run \u001B[38;5;28;01mas\u001B[39;00m Run\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Text \u001B[38;5;28;01mas\u001B[39;00m Text\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmessage\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Message \u001B[38;5;28;01mas\u001B[39;00m Message\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/types/beta/threads/run.py:12\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01massistant_tool_choice_option\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AssistantToolChoiceOption\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01massistant_response_format_option\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AssistantResponseFormatOption\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mrequired_action_function_tool_call\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m RequiredActionFunctionToolCall\n\u001B[32m     14\u001B[39m __all__ = [\n\u001B[32m     15\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mRun\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     16\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mIncompleteDetails\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     21\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mUsage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     22\u001B[39m ]\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mIncompleteDetails\u001B[39;00m(BaseModel):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/openai/types/beta/threads/required_action_function_tool_call.py:10\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_models\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseModel\n\u001B[32m      7\u001B[39m __all__ = [\u001B[33m\"\u001B[39m\u001B[33mRequiredActionFunctionToolCall\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mFunction\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43;01mFunction\u001B[39;49;00m\u001B[43m(\u001B[49m\u001B[43mBaseModel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43marguments\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\n\u001B[32m     12\u001B[39m \u001B[38;5;250;43m    \u001B[39;49m\u001B[33;43;03m\"\"\"The arguments that the model expects you to pass to the function.\"\"\"\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:175\u001B[39m, in \u001B[36mModelMetaclass.__new__\u001B[39m\u001B[34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001B[39m\n\u001B[32m    169\u001B[39m \u001B[38;5;28mcls\u001B[39m.__pydantic_post_init__ = (\n\u001B[32m    170\u001B[39m     \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m.model_post_init \u001B[38;5;129;01mis\u001B[39;00m BaseModel_.model_post_init \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mmodel_post_init\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    171\u001B[39m )\n\u001B[32m    173\u001B[39m \u001B[38;5;28mcls\u001B[39m.__pydantic_setattr_handlers__ = {}\n\u001B[32m--> \u001B[39m\u001B[32m175\u001B[39m \u001B[38;5;28mcls\u001B[39m.__pydantic_decorators__ = \u001B[43mDecoratorInfos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[38;5;28mcls\u001B[39m.__pydantic_decorators__.update_from_config(config_wrapper)\n\u001B[32m    178\u001B[39m \u001B[38;5;66;03m# Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/litellm-agentic-examples/.venv/lib/python3.12/site-packages/pydantic/_internal/_decorators.py:445\u001B[39m, in \u001B[36mDecoratorInfos.build\u001B[39m\u001B[34m(model_dc)\u001B[39m\n\u001B[32m    432\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"We want to collect all DecFunc instances that exist as\u001B[39;00m\n\u001B[32m    433\u001B[39m \u001B[33;03mattributes in the namespace of the class (a BaseModel or dataclass)\u001B[39;00m\n\u001B[32m    434\u001B[39m \u001B[33;03mthat called us\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    442\u001B[39m \u001B[33;03mthe replaced function was in; that is, we maintain the order.\u001B[39;00m\n\u001B[32m    443\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    444\u001B[39m \u001B[38;5;66;03m# reminder: dicts are ordered and replacement does not alter the order\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m445\u001B[39m res = \u001B[43mDecoratorInfos\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    446\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m base \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(mro(model_dc)[\u001B[32m1\u001B[39m:]):\n\u001B[32m    447\u001B[39m     existing: DecoratorInfos | \u001B[38;5;28;01mNone\u001B[39;00m = base.\u001B[34m__dict__\u001B[39m.get(\u001B[33m'\u001B[39m\u001B[33m__pydantic_decorators__\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<string>:8\u001B[39m, in \u001B[36m__init__\u001B[39m\u001B[34m(self, validators, field_validators, root_validators, field_serializers, model_serializers, model_validators, computed_fields)\u001B[39m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "import os\n",
    "import litellm\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from agentscope.model import OpenAIChatModel\n",
    "from agentscope.tool import ToolResponse, Toolkit\n",
    "from agentscope.message import TextBlock\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.message import Msg"
   ],
   "id": "b3f5fa03d417688a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load your credentials as environment variables.",
   "id": "d20a325453af7922"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e931b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"LITELLM_ROXY_URL\")\n",
    "api_key = os.getenv(\"LITELLM_MASTER_KEY\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up the model with your proxy params",
   "id": "1488cf79b30e71ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sap_model = OpenAIChatModel(model_name='sap/gpt-4o',\n",
    "                            api_key=api_key,\n",
    "                            client_args={\"base_url\": api_base},\n",
    "                            stream=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the agent tools with a properly formatted docstring. Including the Args section is necessary for the correct functioning of the tool. Also the function must return its response as a ToolResponse object.",
   "id": "d8c2357ecd49050f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_weather(city: str) -> ToolResponse:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "    Args:\n",
    "        city (str): The name of the city to retrieve weather information for.\n",
    "            Examples: \"New York\", \"London\", \"Tokyo\".\n",
    "    \"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return ToolResponse(content=[\n",
    "            TextBlock(type=\"text\",\n",
    "                      text=mock_weather_db[city_normalized])\n",
    "        ])\n",
    "    else:\n",
    "        return ToolResponse(content=[\n",
    "            TextBlock(type=\"text\",\n",
    "                      text=f\"The weather in {city} is sunny with a temperature of 20째C.\")\n",
    "        ])"
   ],
   "id": "fcb264460a6acfe3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Register the tools in a toolkit",
   "id": "8f678cf6b2cc3eee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "toolkit = Toolkit()\n",
    "toolkit.register_tool_function(get_weather)"
   ],
   "id": "fcbad89575f9189d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the Agent with the SAP LLM and the tool, memory and formatter objects.",
   "id": "25c8f76ac746be91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent(\n",
    "        name=\"weather agent\",\n",
    "        sys_prompt=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, write a couple sentences for \"\n",
    "                \"TV weather report in the city, that will be include small jok\",\n",
    "        model=sap_model,\n",
    "        formatter=DashScopeChatFormatter(),\n",
    "        toolkit=toolkit,\n",
    "        memory=InMemoryMemory(),\n",
    "    )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a message",
   "id": "41084e27e3d35b72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e909669",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "msg = Msg(\n",
    "        name=\"user\",\n",
    "        content=\"What is the weather like in Tbilisi?\",\n",
    "        role=\"user\",\n",
    "    )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run agent inside the async function",
   "id": "78543e6c51ef5ddd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4394b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def run_conversation():\n",
    "    result = await agent(msg)\n",
    "    print(result)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run the conversation function",
   "id": "910180b1e68326dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cad2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(run_conversation())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
