{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb4f4ab484ea4c8",
   "metadata": {},
   "source": [
    "# AgentScope example connecting to Sap Generative AI Hub via LiteLLM\n",
    "\n",
    "## [How AgentScope works](https://doc.agentscope.io/tutorial/)\n",
    "\n",
    "## LLM access via LiteLLM Proxy\n",
    "AgentScope supports the [LiteLLM Proxy](https://docs.litellm.ai/docs/simple_proxy) for access via OpenAI API calls.\n",
    "\n",
    "Follow details in [LiteLLM Proxy setup for SAP Gen. AI Hub](../proxy_set_up.ipynb)\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197b4fa4dc2f4943",
   "metadata": {},
   "source": [
    "%pip install agentscope litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102631d376927ee7",
   "metadata": {},
   "source": [
    "## Set env variables\n",
    "Add the following variables from the service key in a file called \".env\" and put it in the same folder where you run the notebook:\n",
    "```\n",
    "LITELLM_PROXY_API_KEY=sk-1234\n",
    "PROXY_BASE_URL=http://localhost:4000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fd62825f8b955",
   "metadata": {},
   "source": [
    "## Run the AgentScope with LiteLLM and SAP LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5fa03d417688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "import litellm\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.message import Msg, TextBlock\n",
    "from agentscope.model import OpenAIChatModel\n",
    "from agentscope.tool import Toolkit, ToolResponse\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a325453af7922",
   "metadata": {},
   "source": [
    "Load your credentials as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e931b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"PROXY_BASE_URL\")\n",
    "api_key = os.getenv(\"LITELLM_PROXY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488cf79b30e71ed",
   "metadata": {},
   "source": [
    "Set up the model with your proxy params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sap_model = OpenAIChatModel(model_name='sap/gpt-4o',\n",
    "                            api_key=api_key,\n",
    "                            client_args={\"base_url\": api_base},\n",
    "                            stream=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2357ecd49050f",
   "metadata": {},
   "source": [
    "Define the agent tools with a properly formatted docstring. Including the Args section is necessary for the correct functioning of the tool. Also the function must return its response as a ToolResponse object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb264460a6acfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> ToolResponse:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "    Args:\n",
    "        city (str): The name of the city to retrieve weather information for.\n",
    "            Examples: \"New York\", \"London\", \"Tokyo\".\n",
    "    \"\"\"\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25째C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15째C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18째C.\",\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return ToolResponse(content=[\n",
    "            TextBlock(type=\"text\",\n",
    "                      text=mock_weather_db[city_normalized])\n",
    "        ])\n",
    "    else:\n",
    "        return ToolResponse(content=[\n",
    "            TextBlock(type=\"text\",\n",
    "                      text=f\"The weather in {city} is sunny with a temperature of 20째C.\")\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f678cf6b2cc3eee",
   "metadata": {},
   "source": [
    "Register the tools in a toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbad89575f9189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = Toolkit()\n",
    "toolkit.register_tool_function(get_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c8f76ac746be91",
   "metadata": {},
   "source": [
    "Define the Agent with the SAP LLM and the tool, memory and formatter objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent(\n",
    "        name=\"weather agent\",\n",
    "        sys_prompt=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, write a couple of sentences for a \"\n",
    "                \"TV weather report in the city including a small joke.\",\n",
    "        model=sap_model,\n",
    "        formatter=DashScopeChatFormatter(),\n",
    "        toolkit=toolkit,\n",
    "        memory=InMemoryMemory(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41084e27e3d35b72",
   "metadata": {},
   "source": [
    "Create a message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e909669",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "msg = Msg(\n",
    "        name=\"user\",\n",
    "        content=\"What is the weather like in Tbilisi?\",\n",
    "        role=\"user\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78543e6c51ef5ddd",
   "metadata": {},
   "source": [
    "Run agent inside the async function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4394b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def run_conversation():\n",
    "    result = await agent(msg)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910180b1e68326dc",
   "metadata": {},
   "source": [
    "Run the conversation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cad2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_conversation()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
